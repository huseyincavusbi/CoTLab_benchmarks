============================================================
Configuration:
============================================================
backend:
  _target_: cotlab.backends.TransformersBackend
  device: cuda
  dtype: bfloat16
  enable_hooks: true
  trust_remote_code: true
model:
  name: google/medgemma-27b-text-it
  variant: 27b-text
  max_new_tokens: 512
  temperature: 0.7
  top_p: 0.9
  safe_name: medgemma_27b_text_it
prompt:
  _target_: cotlab.prompts.mcq.MCQPromptStrategy
  name: mcq
  few_shot: true
  output_format: json
  answer_first: false
  contrarian: false
dataset:
  _target_: cotlab.datasets.loaders.MedQADataset
  name: medxpertqa
  filename: medxpertqa/test.jsonl
  split: test
experiment:
  _target_: cotlab.experiments.AttentionAnalysisExperiment
  name: attention_analysis
  description: Analyze attention patterns at critical layers
  all_layers: true
  target_layers: null
  layer_stride: 1
  force_eager_reload: false
  num_samples: null
  last_k_tokens: 16
  max_input_tokens: 1024
  analyze_generated_tokens: false
  generated_max_new_tokens: 16
  generated_do_sample: false
  generated_temperature: 0.7
  generated_top_p: 0.9
  question: Patient presents with chest pain, sweating, and shortness of breath. What
    is the diagnosis?
  batch_size: 16
seed: 42
verbose: true
dry_run: false

============================================================
Created experiment documentation: /root/CoTLab/CoTLab/outputs/2026-02-26/16-28-57_attention_analysis_medgemma_27b_text_it_mcq_json_medxpertqa/EXPERIMENT.md
Loading backend: cotlab.backends.TransformersBackend
Loading model: google/medgemma-27b-text-it
  Device map: cuda
  Dtype: torch.bfloat16
  Cache: ~/.cache/huggingface (HF default)
Loading checkpoint shards:   0%|                                           | 0/11 [00:00<?, ?it/s]Loading checkpoint shards:   9%|███▏                               | 1/11 [00:00<00:06,  1.47it/s]Loading checkpoint shards:  18%|██████▎                            | 2/11 [00:01<00:06,  1.44it/s]Loading checkpoint shards:  27%|█████████▌                         | 3/11 [00:02<00:05,  1.43it/s]Loading checkpoint shards:  36%|████████████▋                      | 4/11 [00:02<00:04,  1.43it/s]Loading checkpoint shards:  45%|███████████████▉                   | 5/11 [00:03<00:04,  1.43it/s]Loading checkpoint shards:  55%|███████████████████                | 6/11 [00:04<00:03,  1.42it/s]Loading checkpoint shards:  64%|██████████████████████▎            | 7/11 [00:04<00:02,  1.42it/s]Loading checkpoint shards:  73%|█████████████████████████▍         | 8/11 [00:05<00:02,  1.42it/s]Loading checkpoint shards:  82%|████████████████████████████▋      | 9/11 [00:06<00:01,  1.42it/s]Loading checkpoint shards:  91%|██████████████████████████████▉   | 10/11 [00:07<00:00,  1.42it/s]Loading checkpoint shards: 100%|██████████████████████████████████| 11/11 [00:07<00:00,  1.45it/s]Loading checkpoint shards: 100%|██████████████████████████████████| 11/11 [00:07<00:00,  1.43it/s]
  Resolved device: cuda:0
Creating prompt strategy: mcq
Loading dataset: medxpertqa
test.jsonl: 0.00B [00:00, ?B/s]test.jsonl: 2.46MB [00:00, 24.4MB/s]test.jsonl: 4.26MB [00:00, 26.3MB/s]
Creating experiment: attention_analysis
============================================================
Running experiment: attention_analysis
============================================================
Model: google/medgemma-27b-text-it
Attention heads: 32
All layers enabled: True
Layer stride: 1
Resolved layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]
Max input tokens: 1024
Batch size: 16
Analyze generated tokens: False
Current attention implementation: sdpa
Switching attention implementation to 'eager' in-place...

Analyzing attention on 2450 samples (batch_size=16)...
Processing batches:   0%|                                                 | 0/154 [00:00<?, ?it/s]Processing batches:   1%|▎                                        | 1/154 [00:07<18:51,  7.39s/it]Processing batches:   1%|▌                                        | 2/154 [00:14<18:19,  7.23s/it]Processing batches:   2%|▊                                        | 3/154 [00:21<18:06,  7.19s/it]Processing batches:   3%|█                                        | 4/154 [00:28<17:42,  7.09s/it]Processing batches:   3%|█▎                                       | 5/154 [00:35<17:42,  7.13s/it]Processing batches:   4%|█▌                                       | 6/154 [00:42<17:35,  7.13s/it]Processing batches:   5%|█▊                                       | 7/154 [00:50<17:28,  7.14s/it]Processing batches:   5%|██▏                                      | 8/154 [00:57<17:21,  7.13s/it]Processing batches:   6%|██▍                                      | 9/154 [01:04<17:08,  7.09s/it]Processing batches:   6%|██▌                                     | 10/154 [01:11<17:02,  7.10s/it]Processing batches:   7%|██▊                                     | 11/154 [01:18<16:56,  7.11s/it]Processing batches:   8%|███                                     | 12/154 [01:25<16:50,  7.12s/it]Processing batches:   8%|███▍                                    | 13/154 [01:32<16:45,  7.13s/it]Processing batches:   9%|███▋                                    | 14/154 [01:39<16:38,  7.14s/it]Processing batches:  10%|███▉                                    | 15/154 [01:47<16:32,  7.14s/it]Processing batches:  10%|████▏                                   | 16/154 [01:54<16:27,  7.16s/it]Processing batches:  11%|████▍                                   | 17/154 [02:01<16:18,  7.14s/it]Processing batches:  12%|████▋                                   | 18/154 [02:08<16:18,  7.20s/it]Processing batches:  12%|████▉                                   | 19/154 [02:15<16:09,  7.18s/it]Processing batches:  13%|█████▏                                  | 20/154 [02:23<16:02,  7.19s/it]Processing batches:  14%|█████▍                                  | 21/154 [02:30<15:49,  7.14s/it]Processing batches:  14%|█████▋                                  | 22/154 [02:37<15:42,  7.14s/it]Processing batches:  15%|█████▉                                  | 23/154 [02:44<15:35,  7.14s/it]Processing batches:  16%|██████▏                                 | 24/154 [02:51<15:29,  7.15s/it]Processing batches:  16%|██████▍                                 | 25/154 [02:58<15:22,  7.15s/it]Processing batches:  17%|██████▊                                 | 26/154 [03:05<15:15,  7.15s/it]Processing batches:  18%|███████                                 | 27/154 [03:13<15:10,  7.17s/it]Processing batches:  18%|███████▎                                | 28/154 [03:20<15:05,  7.19s/it]Processing batches:  19%|███████▌                                | 29/154 [03:27<14:58,  7.18s/it]Processing batches:  19%|███████▊                                | 30/154 [03:34<14:50,  7.18s/it]Processing batches:  20%|████████                                | 31/154 [03:41<14:41,  7.17s/it]Processing batches:  21%|████████▎                               | 32/154 [03:48<14:34,  7.17s/it]Processing batches:  21%|████████▌                               | 33/154 [03:56<14:27,  7.17s/it]Processing batches:  22%|████████▊                               | 34/154 [04:03<14:19,  7.17s/it]Processing batches:  23%|█████████                               | 35/154 [04:10<14:12,  7.17s/it]Processing batches:  23%|█████████▎                              | 36/154 [04:17<14:05,  7.17s/it]Processing batches:  24%|█████████▌                              | 37/154 [04:24<13:59,  7.17s/it]Processing batches:  25%|█████████▊                              | 38/154 [04:31<13:52,  7.18s/it]Processing batches:  25%|██████████▏                             | 39/154 [04:39<13:44,  7.17s/it]Processing batches:  26%|██████████▍                             | 40/154 [04:46<13:37,  7.17s/it]Processing batches:  27%|██████████▋                             | 41/154 [04:53<13:28,  7.15s/it]Processing batches:  27%|██████████▉                             | 42/154 [05:00<13:22,  7.16s/it]Processing batches:  28%|███████████▏                            | 43/154 [05:07<13:15,  7.17s/it]Processing batches:  29%|███████████▍                            | 44/154 [05:15<13:18,  7.26s/it]Processing batches:  29%|███████████▋                            | 45/154 [05:22<13:11,  7.26s/it]Processing batches:  30%|███████████▉                            | 46/154 [05:29<13:02,  7.25s/it]Processing batches:  31%|████████████▏                           | 47/154 [05:36<12:52,  7.22s/it]Processing batches:  31%|████████████▍                           | 48/154 [05:44<12:44,  7.21s/it]Processing batches:  32%|████████████▋                           | 49/154 [05:51<12:36,  7.20s/it]Processing batches:  32%|████████████▉                           | 50/154 [05:58<12:27,  7.19s/it]Processing batches:  33%|█████████████▏                          | 51/154 [06:05<12:19,  7.18s/it]Processing batches:  34%|█████████████▌                          | 52/154 [06:12<12:12,  7.18s/it]Processing batches:  34%|█████████████▊                          | 53/154 [06:19<12:05,  7.19s/it]Processing batches:  35%|██████████████                          | 54/154 [06:27<11:57,  7.18s/it]Processing batches:  36%|██████████████▎                         | 55/154 [06:34<11:49,  7.17s/it]Processing batches:  36%|██████████████▌                         | 56/154 [06:41<11:41,  7.16s/it]Processing batches:  37%|██████████████▊                         | 57/154 [06:48<11:34,  7.16s/it]Processing batches:  38%|███████████████                         | 58/154 [06:55<11:28,  7.17s/it]Processing batches:  38%|███████████████▎                        | 59/154 [07:02<11:21,  7.18s/it]Processing batches:  39%|███████████████▌                        | 60/154 [07:10<11:13,  7.17s/it]Processing batches:  40%|███████████████▊                        | 61/154 [07:17<11:07,  7.17s/it]Processing batches:  40%|████████████████                        | 62/154 [07:24<11:00,  7.18s/it]Processing batches:  41%|████████████████▎                       | 63/154 [07:31<10:52,  7.18s/it]Processing batches:  42%|████████████████▌                       | 64/154 [07:38<10:45,  7.18s/it]Processing batches:  42%|████████████████▉                       | 65/154 [07:45<10:38,  7.18s/it]Processing batches:  43%|█████████████████▏                      | 66/154 [07:53<10:33,  7.19s/it]Processing batches:  44%|█████████████████▍                      | 67/154 [08:00<10:25,  7.19s/it]Processing batches:  44%|█████████████████▋                      | 68/154 [08:07<10:17,  7.18s/it]Processing batches:  45%|█████████████████▉                      | 69/154 [08:14<10:11,  7.20s/it]Processing batches:  45%|██████████████████▏                     | 70/154 [08:22<10:05,  7.20s/it]Processing batches:  46%|██████████████████▍                     | 71/154 [08:29<09:57,  7.19s/it]Processing batches:  47%|██████████████████▋                     | 72/154 [08:36<09:49,  7.18s/it]Processing batches:  47%|██████████████████▉                     | 73/154 [08:43<09:41,  7.18s/it]Processing batches:  48%|███████████████████▏                    | 74/154 [08:50<09:34,  7.18s/it]Processing batches:  49%|███████████████████▍                    | 75/154 [08:57<09:27,  7.19s/it]Processing batches:  49%|███████████████████▋                    | 76/154 [09:05<09:20,  7.19s/it]Processing batches:  50%|████████████████████                    | 77/154 [09:12<09:22,  7.30s/it]Processing batches:  51%|████████████████████▎                   | 78/154 [09:19<09:12,  7.26s/it]Processing batches:  51%|████████████████████▌                   | 79/154 [09:27<09:02,  7.24s/it]Processing batches:  52%|████████████████████▊                   | 80/154 [09:34<08:54,  7.22s/it]Processing batches:  53%|█████████████████████                   | 81/154 [09:41<08:45,  7.20s/it]Processing batches:  53%|█████████████████████▎                  | 82/154 [09:48<08:37,  7.19s/it]Processing batches:  54%|█████████████████████▌                  | 83/154 [09:55<08:30,  7.18s/it]Processing batches:  55%|█████████████████████▊                  | 84/154 [10:02<08:22,  7.18s/it]Processing batches:  55%|██████████████████████                  | 85/154 [10:10<08:15,  7.18s/it]Processing batches:  56%|██████████████████████▎                 | 86/154 [10:17<08:07,  7.17s/it]Processing batches:  56%|██████████████████████▌                 | 87/154 [10:24<08:00,  7.17s/it]Processing batches:  57%|██████████████████████▊                 | 88/154 [10:31<07:55,  7.20s/it]Processing batches:  58%|███████████████████████                 | 89/154 [10:38<07:47,  7.20s/it]Processing batches:  58%|███████████████████████▍                | 90/154 [10:45<07:40,  7.19s/it]Processing batches:  59%|███████████████████████▋                | 91/154 [10:53<07:32,  7.18s/it]Processing batches:  60%|███████████████████████▉                | 92/154 [11:00<07:25,  7.18s/it]Processing batches:  60%|████████████████████████▏               | 93/154 [11:07<07:17,  7.17s/it]Processing batches:  61%|████████████████████████▍               | 94/154 [11:14<07:10,  7.17s/it]Processing batches:  62%|████████████████████████▋               | 95/154 [11:21<07:03,  7.17s/it]Processing batches:  62%|████████████████████████▉               | 96/154 [11:28<06:55,  7.16s/it]Processing batches:  63%|█████████████████████████▏              | 97/154 [11:36<06:48,  7.17s/it]Processing batches:  64%|█████████████████████████▍              | 98/154 [11:43<06:41,  7.16s/it]Processing batches:  64%|█████████████████████████▋              | 99/154 [11:50<06:34,  7.17s/it]Processing batches:  65%|█████████████████████████▎             | 100/154 [11:57<06:27,  7.17s/it]Processing batches:  66%|█████████████████████████▌             | 101/154 [12:04<06:20,  7.17s/it]Processing batches:  66%|█████████████████████████▊             | 102/154 [12:11<06:12,  7.16s/it]Processing batches:  67%|██████████████████████████             | 103/154 [12:19<06:04,  7.15s/it]Processing batches:  68%|██████████████████████████▎            | 104/154 [12:26<05:57,  7.16s/it]Processing batches:  68%|██████████████████████████▌            | 105/154 [12:33<05:50,  7.16s/it]Processing batches:  69%|██████████████████████████▊            | 106/154 [12:40<05:43,  7.16s/it]Processing batches:  69%|███████████████████████████            | 107/154 [12:47<05:36,  7.17s/it]Processing batches:  70%|███████████████████████████▎           | 108/154 [12:54<05:29,  7.17s/it]Processing batches:  71%|███████████████████████████▌           | 109/154 [13:02<05:22,  7.17s/it]Processing batches:  71%|███████████████████████████▊           | 110/154 [13:09<05:15,  7.16s/it]Processing batches:  72%|████████████████████████████           | 111/154 [13:16<05:07,  7.16s/it]Processing batches:  73%|████████████████████████████▎          | 112/154 [13:23<05:00,  7.16s/it]Processing batches:  73%|████████████████████████████▌          | 113/154 [13:30<04:53,  7.17s/it]Processing batches:  74%|████████████████████████████▊          | 114/154 [13:37<04:46,  7.17s/it]Processing batches:  75%|█████████████████████████████          | 115/154 [13:45<04:39,  7.17s/it]Processing batches:  75%|█████████████████████████████▍         | 116/154 [13:52<04:32,  7.17s/it]Processing batches:  76%|█████████████████████████████▋         | 117/154 [14:00<04:31,  7.34s/it]Processing batches:  77%|█████████████████████████████▉         | 118/154 [14:07<04:23,  7.31s/it]Processing batches:  77%|██████████████████████████████▏        | 119/154 [14:14<04:14,  7.27s/it]Processing batches:  78%|██████████████████████████████▍        | 120/154 [14:21<04:05,  7.23s/it]Processing batches:  79%|██████████████████████████████▋        | 121/154 [14:28<03:57,  7.21s/it]Processing batches:  79%|██████████████████████████████▉        | 122/154 [14:35<03:50,  7.20s/it]Processing batches:  80%|███████████████████████████████▏       | 123/154 [14:43<03:43,  7.19s/it]Processing batches:  81%|███████████████████████████████▍       | 124/154 [14:50<03:35,  7.19s/it]Processing batches:  81%|███████████████████████████████▋       | 125/154 [14:57<03:28,  7.19s/it]Processing batches:  82%|███████████████████████████████▉       | 126/154 [15:04<03:21,  7.18s/it]Processing batches:  82%|████████████████████████████████▏      | 127/154 [15:11<03:13,  7.18s/it]Processing batches:  83%|████████████████████████████████▍      | 128/154 [15:18<03:06,  7.18s/it]Processing batches:  84%|████████████████████████████████▋      | 129/154 [15:26<02:59,  7.19s/it]Processing batches:  84%|████████████████████████████████▉      | 130/154 [15:33<02:52,  7.21s/it]Processing batches:  85%|█████████████████████████████████▏     | 131/154 [15:40<02:45,  7.19s/it]Processing batches:  86%|█████████████████████████████████▍     | 132/154 [15:47<02:37,  7.18s/it]Processing batches:  86%|█████████████████████████████████▋     | 133/154 [15:54<02:31,  7.19s/it]Processing batches:  87%|█████████████████████████████████▉     | 134/154 [16:02<02:23,  7.18s/it]Processing batches:  88%|██████████████████████████████████▏    | 135/154 [16:09<02:16,  7.18s/it]Processing batches:  88%|██████████████████████████████████▍    | 136/154 [16:16<02:09,  7.19s/it]Processing batches:  89%|██████████████████████████████████▋    | 137/154 [16:23<02:02,  7.18s/it]Processing batches:  90%|██████████████████████████████████▉    | 138/154 [16:30<01:54,  7.18s/it]Processing batches:  90%|███████████████████████████████████▏   | 139/154 [16:38<01:47,  7.17s/it]Processing batches:  91%|███████████████████████████████████▍   | 140/154 [16:45<01:40,  7.19s/it]Processing batches:  92%|███████████████████████████████████▋   | 141/154 [16:52<01:33,  7.19s/it]Processing batches:  92%|███████████████████████████████████▉   | 142/154 [16:59<01:26,  7.18s/it]Processing batches:  93%|████████████████████████████████████▏  | 143/154 [17:06<01:18,  7.17s/it]Processing batches:  94%|████████████████████████████████████▍  | 144/154 [17:13<01:11,  7.19s/it]Processing batches:  94%|████████████████████████████████████▋  | 145/154 [17:21<01:04,  7.18s/it]Processing batches:  95%|████████████████████████████████████▉  | 146/154 [17:28<00:57,  7.18s/it]Processing batches:  95%|█████████████████████████████████████▏ | 147/154 [17:35<00:50,  7.17s/it]Processing batches:  96%|█████████████████████████████████████▍ | 148/154 [17:42<00:43,  7.17s/it]Processing batches:  97%|█████████████████████████████████████▋ | 149/154 [17:49<00:35,  7.19s/it]Processing batches:  97%|█████████████████████████████████████▉ | 150/154 [17:57<00:28,  7.19s/it]Processing batches:  98%|██████████████████████████████████████▏| 151/154 [18:04<00:21,  7.19s/it]Processing batches:  99%|██████████████████████████████████████▍| 152/154 [18:11<00:14,  7.20s/it]Processing batches:  99%|██████████████████████████████████████▋| 153/154 [18:18<00:07,  7.19s/it]Processing batches: 100%|███████████████████████████████████████| 154/154 [18:19<00:00,  5.30s/it]Processing batches: 100%|███████████████████████████████████████| 154/154 [18:19<00:00,  7.14s/it]

======================================================================
ATTENTION ANALYSIS: Aggregated Statistics Across Samples
======================================================================
Layer    | LastTok μ  | AllTok μ   | Last16 μ   | AllTok σ   | Top Tokens
----------------------------------------------------------------------------------------------------------
L0       | 3.8695     | 3.4952     | 4.2642     | 0.0814     | ',', '.', ' of'
L1       | 1.8222     | 1.5022     | 1.9170     | 0.0967     | ' ', '<bos>', '.'
L2       | 1.8440     | 1.4730     | 2.0876     | 0.1426     | ' ', '<bos>', '.'
L3       | 0.5747     | 0.3100     | 0.5514     | 0.0807     | '.', ' answer', ' '
L4       | 1.1773     | 0.9800     | 1.2441     | 0.0395     | ' ', '<bos>', '.'
L5       | 1.4704     | 1.1249     | 1.3657     | 0.0339     | ' ', '<bos>', ' in'
L6       | 2.0294     | 1.5658     | 2.0777     | 0.1456     | ' ', '<bos>', ' ('
L7       | 2.0945     | 1.5970     | 2.0572     | 0.0818     | ' ', '.', ' correct'
L8       | 2.3261     | 1.7930     | 2.2133     | 0.0923     | '.', ' answer', ' '
L9       | 2.0199     | 1.6241     | 2.1234     | 0.0973     | '.', ' answer', '
'
L10      | 2.3214     | 1.7048     | 2.4035     | 0.0938     | '<bos>', ''', ' '
L11      | 1.6678     | 1.5270     | 1.9179     | 0.0625     | ''', '<bos>', ' '
L12      | 1.8613     | 1.2884     | 1.8829     | 0.1225     | ' ', '<bos>', '''
L13      | 2.3260     | 1.5528     | 2.1706     | 0.1156     | ' ', '<bos>', '''
L14      | 2.2577     | 1.6562     | 2.1022     | 0.1038     | '
', '.', ':'
L15      | 2.3058     | 1.5401     | 2.0675     | 0.0848     | ''', '<bos>', ' '
L16      | 2.0302     | 1.6568     | 2.0105     | 0.0605     | '<bos>', ' ', '''
L17      | 2.7023     | 2.1066     | 2.6521     | 0.0634     | '<bos>', ''', ' '
L18      | 3.2324     | 2.6110     | 3.2309     | 0.0797     | ',', '.', ' answer'
L19      | 2.6771     | 2.0378     | 2.5792     | 0.0717     | '<bos>', ' ', '''
L20      | 2.8821     | 2.1831     | 2.7589     | 0.0680     | '.', ' answer', ' D'
L21      | 2.9403     | 2.3762     | 2.8473     | 0.0785     | '.', '```', ' answer'
L22      | 3.0943     | 2.3506     | 2.8672     | 0.0683     | '.', ' answer', ' of'
L23      | 3.1688     | 2.6247     | 3.0777     | 0.0745     | '<bos>', '```', ' '
L24      | 3.4529     | 2.6863     | 3.2872     | 0.0635     | '.', ' answer', '"}'
L25      | 3.4904     | 2.8012     | 3.2773     | 0.0556     | '
', '.', ' answer'
L26      | 3.5576     | 2.7951     | 3.3895     | 0.0657     | '```', '.', ' '
L27      | 3.3515     | 2.7559     | 3.2347     | 0.0806     | ':', '.', ' ...)'
L28      | 3.4378     | 2.7277     | 3.3561     | 0.0678     | ' ', '<bos>', '''
L29      | 2.8068     | 2.2571     | 2.8073     | 0.0558     | '<bos>', ' ', '```'
L30      | 2.9311     | 2.3577     | 2.9193     | 0.0753     | ' ', '<bos>', '",'
L31      | 2.8993     | 2.1005     | 2.7291     | 0.0820     | ' ', '<bos>', '```'
L32      | 2.6373     | 1.9088     | 2.5006     | 0.0839     | ' ', '<bos>', '.'
L33      | 2.8287     | 1.9515     | 2.5991     | 0.0882     | ' ', '<bos>', '.'
L34      | 2.3947     | 1.6818     | 2.2027     | 0.0860     | ' ', '<bos>', '.'
L35      | 2.9965     | 2.1233     | 2.8257     | 0.0726     | ' ', '<bos>', '```'
L36      | 2.7488     | 2.0455     | 2.5366     | 0.0797     | ' ', '<bos>', '.'
L37      | 2.7936     | 1.9521     | 2.6746     | 0.0756     | ' ', '<bos>', 'g'
L38      | 2.3905     | 1.4834     | 2.0280     | 0.0912     | ' ', '<bos>', '.'
L39      | 2.1968     | 1.3636     | 1.9094     | 0.0951     | ' ', '<bos>', 'Where'
L40      | 1.5115     | 0.7384     | 1.3719     | 0.1144     | ' ', '<bos>', ' answer'
L41      | 1.9465     | 1.0048     | 1.6655     | 0.0738     | ' ', '<bos>', '##'
L42      | 2.3471     | 1.4001     | 2.0355     | 0.1002     | ' ', '<bos>', 'json'
L43      | 1.6022     | 0.9999     | 1.6072     | 0.1117     | ' ', '<bos>', '.'
L44      | 1.6170     | 1.0270     | 1.5519     | 0.1097     | ' ', '<bos>', '.'
L45      | 1.7320     | 0.9472     | 1.5612     | 0.1135     | ' ', '<bos>', ' "'
L46      | 1.6427     | 1.0369     | 1.6438     | 0.1058     | ' ', '<bos>', '.'
L47      | 2.4923     | 1.4723     | 2.5505     | 0.0868     | ' ', '<bos>', '.'
L48      | 1.3658     | 0.6493     | 1.3861     | 0.1218     | ' ', '<bos>', '.'
L49      | 1.3632     | 0.6490     | 1.2777     | 0.1212     | ' ', '<bos>', '.'
L50      | 1.2390     | 0.6689     | 1.2685     | 0.1180     | ' ', '<bos>', ' answer'
L51      | 1.5454     | 0.8717     | 1.5481     | 0.1147     | ' ', '<bos>', ' answer'
L52      | 1.7884     | 1.1461     | 1.6648     | 0.1006     | ' ', '<bos>', '.'
L53      | 2.3763     | 1.4036     | 2.2556     | 0.0838     | ' ', '<bos>', '
'
L54      | 2.2696     | 1.6804     | 2.1681     | 0.0893     | ' ', '<bos>', '```'
L55      | 2.4442     | 1.5792     | 2.2072     | 0.0956     | ' ', '<bos>', '''
L56      | 1.9407     | 1.3886     | 1.8354     | 0.0912     | ' ', '<bos>', '.'
L57      | 1.4255     | 0.7914     | 1.3467     | 0.1105     | ' ', '<bos>', '.'
L58      | 2.7441     | 1.8521     | 2.3680     | 0.0863     | ' ', '.', '<bos>'
L59      | 2.4600     | 1.4333     | 2.1324     | 0.0914     | ' ', '<bos>', '```'
L60      | 1.9625     | 1.3196     | 1.8424     | 0.0895     | ' ', '<bos>', '.'
L61      | 1.9545     | 1.3676     | 1.7984     | 0.0735     | '<bos>', '.', ' '
----------------------------------------------------------------------------------------------------------

Overall mean entropy (all tokens): 1.6629
Overall mean entropy (last token): 2.3126
Overall mean entropy (last 16 tokens): 2.2231
Most focused layer (all tokens): L3 (entropy: 0.3100)

Results saved to: /root/CoTLab/CoTLab/outputs/2026-02-26/16-28-57_attention_analysis_medgemma_27b_text_it_mcq_json_medxpertqa/results.json

Metrics:
  num_samples_analyzed: 2450
  num_layers_analyzed: 62
  num_heads: 32
  overall_mean_entropy: 1.6628989420950926
  overall_mean_entropy_all_tokens: 1.6628989420950926
  overall_mean_entropy_last_token: 2.312586066616024
  overall_mean_entropy_last_k_tokens: 2.2231306665190305
  last_k_tokens: 16
  most_focused_layer: 3
  most_focused_entropy: 0.3099725114569617
  most_focused_layer_all_tokens: 3
  most_focused_entropy_all_tokens: 0.3099725114569617
  most_focused_layer_last_token: 3
  most_focused_entropy_last_token: 0.574708723711588
  analyze_generated_tokens: False

Experiment documentation updated: /root/CoTLab/CoTLab/outputs/2026-02-26/16-28-57_attention_analysis_medgemma_27b_text_it_mcq_json_medxpertqa/EXPERIMENT.md

Experiment complete.
