============================================================
Configuration:
============================================================
backend:
  _target_: cotlab.backends.TransformersBackend
  device: cuda
  dtype: bfloat16
  enable_hooks: true
  trust_remote_code: true
model:
  name: google/medgemma-27b-text-it
  variant: 27b-text
  max_new_tokens: 512
  temperature: 0.7
  top_p: 0.9
  safe_name: medgemma_27b_text_it
prompt:
  _target_: cotlab.prompts.PLABPromptStrategy
  name: plab
  few_shot: false
  output_format: json
  answer_first: false
  contrarian: false
dataset:
  _target_: cotlab.datasets.loaders.PLABDataset
  name: plab
  split: main
  filename: plab/data.json
  topics_filename: plab/topics.json
experiment:
  _target_: cotlab.experiments.AttentionAnalysisExperiment
  name: attention_analysis
  description: Analyze attention patterns at critical layers
  all_layers: true
  target_layers: null
  layer_stride: 1
  force_eager_reload: false
  num_samples: null
  last_k_tokens: 16
  max_input_tokens: 1024
  analyze_generated_tokens: false
  generated_max_new_tokens: 16
  generated_do_sample: false
  generated_temperature: 0.7
  generated_top_p: 0.9
  question: Patient presents with chest pain, sweating, and shortness of breath. What
    is the diagnosis?
  batch_size: 16
seed: 42
verbose: true
dry_run: false

============================================================
Created experiment documentation: /root/CoTLab/CoTLab/outputs/2026-02-26/16-48-23_attention_analysis_medgemma_27b_text_it_plab_json_plab/EXPERIMENT.md
Loading backend: cotlab.backends.TransformersBackend
Loading model: google/medgemma-27b-text-it
  Device map: cuda
  Dtype: torch.bfloat16
  Cache: ~/.cache/huggingface (HF default)
Loading checkpoint shards:   0%|                                           | 0/11 [00:00<?, ?it/s]Loading checkpoint shards:   9%|███▏                               | 1/11 [00:00<00:07,  1.38it/s]Loading checkpoint shards:  18%|██████▎                            | 2/11 [00:01<00:06,  1.40it/s]Loading checkpoint shards:  27%|█████████▌                         | 3/11 [00:02<00:05,  1.41it/s]Loading checkpoint shards:  36%|████████████▋                      | 4/11 [00:02<00:04,  1.41it/s]Loading checkpoint shards:  45%|███████████████▉                   | 5/11 [00:03<00:04,  1.42it/s]Loading checkpoint shards:  55%|███████████████████                | 6/11 [00:04<00:03,  1.42it/s]Loading checkpoint shards:  64%|██████████████████████▎            | 7/11 [00:04<00:02,  1.42it/s]Loading checkpoint shards:  73%|█████████████████████████▍         | 8/11 [00:05<00:02,  1.41it/s]Loading checkpoint shards:  82%|████████████████████████████▋      | 9/11 [00:06<00:01,  1.41it/s]Loading checkpoint shards:  91%|██████████████████████████████▉   | 10/11 [00:07<00:00,  1.42it/s]Loading checkpoint shards: 100%|██████████████████████████████████| 11/11 [00:07<00:00,  1.45it/s]Loading checkpoint shards: 100%|██████████████████████████████████| 11/11 [00:07<00:00,  1.42it/s]
  Resolved device: cuda:0
Creating prompt strategy: plab
Loading dataset: plab
data.json: 0.00B [00:00, ?B/s]data.json: 906kB [00:00, 7.93MB/s]data.json: 1.20MB [00:00, 8.48MB/s]
topics.json: 0.00B [00:00, ?B/s]topics.json: 129kB [00:00, 303MB/s]
Creating experiment: attention_analysis
============================================================
Running experiment: attention_analysis
============================================================
Model: google/medgemma-27b-text-it
Attention heads: 32
All layers enabled: True
Layer stride: 1
Resolved layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]
Max input tokens: 1024
Batch size: 16
Analyze generated tokens: False
Current attention implementation: sdpa
Switching attention implementation to 'eager' in-place...

Analyzing attention on 1652 samples (batch_size=16)...
Processing batches:   0%|                                                 | 0/104 [00:00<?, ?it/s]Processing batches:   1%|▍                                        | 1/104 [00:05<09:34,  5.58s/it]Processing batches:   2%|▊                                        | 2/104 [00:10<09:08,  5.38s/it]Processing batches:   3%|█▏                                       | 3/104 [00:16<08:57,  5.33s/it]Processing batches:   4%|█▌                                       | 4/104 [00:21<08:50,  5.30s/it]Processing batches:   5%|█▉                                       | 5/104 [00:26<08:46,  5.31s/it]Processing batches:   6%|██▎                                      | 6/104 [00:31<08:39,  5.30s/it]Processing batches:   7%|██▊                                      | 7/104 [00:37<08:33,  5.29s/it]Processing batches:   8%|███▏                                     | 8/104 [00:42<08:27,  5.29s/it]Processing batches:   9%|███▌                                     | 9/104 [00:47<08:21,  5.28s/it]Processing batches:  10%|███▊                                    | 10/104 [00:53<08:17,  5.30s/it]Processing batches:  11%|████▏                                   | 11/104 [00:58<08:14,  5.32s/it]Processing batches:  12%|████▌                                   | 12/104 [01:03<08:09,  5.32s/it]Processing batches:  12%|█████                                   | 13/104 [01:09<08:02,  5.30s/it]Processing batches:  13%|█████▍                                  | 14/104 [01:14<08:03,  5.38s/it]Processing batches:  14%|█████▊                                  | 15/104 [01:19<07:54,  5.33s/it]Processing batches:  15%|██████▏                                 | 16/104 [01:25<07:52,  5.37s/it]Processing batches:  16%|██████▌                                 | 17/104 [01:30<07:45,  5.35s/it]Processing batches:  17%|██████▉                                 | 18/104 [01:35<07:39,  5.34s/it]Processing batches:  18%|███████▎                                | 19/104 [01:41<07:31,  5.32s/it]Processing batches:  19%|███████▋                                | 20/104 [01:46<07:27,  5.32s/it]Processing batches:  20%|████████                                | 21/104 [01:51<07:21,  5.32s/it]Processing batches:  21%|████████▍                               | 22/104 [01:57<07:14,  5.30s/it]Processing batches:  22%|████████▊                               | 23/104 [02:02<07:09,  5.30s/it]Processing batches:  23%|█████████▏                              | 24/104 [02:07<07:02,  5.28s/it]Processing batches:  24%|█████████▌                              | 25/104 [02:12<06:56,  5.27s/it]Processing batches:  25%|██████████                              | 26/104 [02:18<06:51,  5.27s/it]Processing batches:  26%|██████████▍                             | 27/104 [02:23<06:46,  5.28s/it]Processing batches:  27%|██████████▊                             | 28/104 [02:28<06:41,  5.28s/it]Processing batches:  28%|███████████▏                            | 29/104 [02:33<06:35,  5.27s/it]Processing batches:  29%|███████████▌                            | 30/104 [02:39<06:29,  5.26s/it]Processing batches:  30%|███████████▉                            | 31/104 [02:44<06:23,  5.26s/it]Processing batches:  31%|████████████▎                           | 32/104 [02:49<06:19,  5.26s/it]Processing batches:  32%|████████████▋                           | 33/104 [02:54<06:12,  5.25s/it]Processing batches:  33%|█████████████                           | 34/104 [03:00<06:06,  5.24s/it]Processing batches:  34%|█████████████▍                          | 35/104 [03:05<06:02,  5.25s/it]Processing batches:  35%|█████████████▊                          | 36/104 [03:10<06:01,  5.31s/it]Processing batches:  36%|██████████████▏                         | 37/104 [03:16<05:54,  5.29s/it]Processing batches:  37%|██████████████▌                         | 38/104 [03:21<05:48,  5.27s/it]Processing batches:  38%|███████████████                         | 39/104 [03:26<05:41,  5.26s/it]Processing batches:  38%|███████████████▍                        | 40/104 [03:32<05:42,  5.35s/it]Processing batches:  39%|███████████████▊                        | 41/104 [03:37<05:35,  5.32s/it]Processing batches:  40%|████████████████▏                       | 42/104 [03:42<05:29,  5.31s/it]Processing batches:  41%|████████████████▌                       | 43/104 [03:48<05:24,  5.32s/it]Processing batches:  42%|████████████████▉                       | 44/104 [03:53<05:18,  5.30s/it]Processing batches:  43%|█████████████████▎                      | 45/104 [03:58<05:11,  5.28s/it]Processing batches:  44%|█████████████████▋                      | 46/104 [04:03<05:06,  5.29s/it]Processing batches:  45%|██████████████████                      | 47/104 [04:09<05:01,  5.30s/it]Processing batches:  46%|██████████████████▍                     | 48/104 [04:14<04:55,  5.28s/it]Processing batches:  47%|██████████████████▊                     | 49/104 [04:19<04:51,  5.30s/it]Processing batches:  48%|███████████████████▏                    | 50/104 [04:25<04:46,  5.30s/it]Processing batches:  49%|███████████████████▌                    | 51/104 [04:30<04:40,  5.30s/it]Processing batches:  50%|████████████████████                    | 52/104 [04:35<04:34,  5.29s/it]Processing batches:  51%|████████████████████▍                   | 53/104 [04:40<04:28,  5.27s/it]Processing batches:  52%|████████████████████▊                   | 54/104 [04:46<04:22,  5.26s/it]Processing batches:  53%|█████████████████████▏                  | 55/104 [04:51<04:17,  5.26s/it]Processing batches:  54%|█████████████████████▌                  | 56/104 [04:56<04:13,  5.27s/it]Processing batches:  55%|█████████████████████▉                  | 57/104 [05:01<04:07,  5.26s/it]Processing batches:  56%|██████████████████████▎                 | 58/104 [05:07<04:01,  5.26s/it]Processing batches:  57%|██████████████████████▋                 | 59/104 [05:12<03:56,  5.26s/it]Processing batches:  58%|███████████████████████                 | 60/104 [05:17<03:51,  5.27s/it]Processing batches:  59%|███████████████████████▍                | 61/104 [05:22<03:46,  5.26s/it]Processing batches:  60%|███████████████████████▊                | 62/104 [05:28<03:40,  5.26s/it]Processing batches:  61%|████████████████████████▏               | 63/104 [05:33<03:37,  5.29s/it]Processing batches:  62%|████████████████████████▌               | 64/104 [05:38<03:31,  5.28s/it]Processing batches:  62%|█████████████████████████               | 65/104 [05:44<03:26,  5.29s/it]Processing batches:  63%|█████████████████████████▍              | 66/104 [05:49<03:20,  5.28s/it]Processing batches:  64%|█████████████████████████▊              | 67/104 [05:54<03:15,  5.28s/it]Processing batches:  65%|██████████████████████████▏             | 68/104 [05:59<03:09,  5.26s/it]Processing batches:  66%|██████████████████████████▌             | 69/104 [06:05<03:08,  5.38s/it]Processing batches:  67%|██████████████████████████▉             | 70/104 [06:10<03:01,  5.34s/it]Processing batches:  68%|███████████████████████████▎            | 71/104 [06:16<02:55,  5.33s/it]Processing batches:  69%|███████████████████████████▋            | 72/104 [06:21<02:50,  5.32s/it]Processing batches:  70%|████████████████████████████            | 73/104 [06:26<02:44,  5.30s/it]Processing batches:  71%|████████████████████████████▍           | 74/104 [06:31<02:38,  5.29s/it]Processing batches:  72%|████████████████████████████▊           | 75/104 [06:37<02:33,  5.28s/it]Processing batches:  73%|█████████████████████████████▏          | 76/104 [06:42<02:27,  5.26s/it]Processing batches:  74%|█████████████████████████████▌          | 77/104 [06:47<02:22,  5.27s/it]Processing batches:  75%|██████████████████████████████          | 78/104 [06:52<02:17,  5.28s/it]Processing batches:  76%|██████████████████████████████▍         | 79/104 [06:58<02:11,  5.26s/it]Processing batches:  77%|██████████████████████████████▊         | 80/104 [07:03<02:06,  5.26s/it]Processing batches:  78%|███████████████████████████████▏        | 81/104 [07:08<02:00,  5.26s/it]Processing batches:  79%|███████████████████████████████▌        | 82/104 [07:13<01:55,  5.25s/it]Processing batches:  80%|███████████████████████████████▉        | 83/104 [07:19<01:50,  5.25s/it]Processing batches:  81%|████████████████████████████████▎       | 84/104 [07:24<01:44,  5.24s/it]Processing batches:  82%|████████████████████████████████▋       | 85/104 [07:29<01:39,  5.24s/it]Processing batches:  83%|█████████████████████████████████       | 86/104 [07:34<01:34,  5.23s/it]Processing batches:  84%|█████████████████████████████████▍      | 87/104 [07:40<01:29,  5.24s/it]Processing batches:  85%|█████████████████████████████████▊      | 88/104 [07:45<01:23,  5.24s/it]Processing batches:  86%|██████████████████████████████████▏     | 89/104 [07:50<01:18,  5.25s/it]Processing batches:  87%|██████████████████████████████████▌     | 90/104 [07:55<01:13,  5.25s/it]Processing batches:  88%|███████████████████████████████████     | 91/104 [08:01<01:08,  5.25s/it]Processing batches:  88%|███████████████████████████████████▍    | 92/104 [08:06<01:03,  5.30s/it]Processing batches:  89%|███████████████████████████████████▊    | 93/104 [08:11<00:58,  5.28s/it]Processing batches:  90%|████████████████████████████████████▏   | 94/104 [08:16<00:52,  5.26s/it]Processing batches:  91%|████████████████████████████████████▌   | 95/104 [08:22<00:47,  5.27s/it]Processing batches:  92%|████████████████████████████████████▉   | 96/104 [08:27<00:42,  5.28s/it]Processing batches:  93%|█████████████████████████████████████▎  | 97/104 [08:32<00:37,  5.31s/it]Processing batches:  94%|█████████████████████████████████████▋  | 98/104 [08:38<00:32,  5.33s/it]