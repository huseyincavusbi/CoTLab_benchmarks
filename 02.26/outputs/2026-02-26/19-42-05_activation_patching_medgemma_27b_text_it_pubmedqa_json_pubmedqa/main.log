============================================================
Configuration:
============================================================
backend:
  _target_: cotlab.backends.TransformersBackend
  device: cuda
  dtype: bfloat16
  enable_hooks: true
  trust_remote_code: true
model:
  name: google/medgemma-27b-text-it
  variant: 27b-text
  max_new_tokens: 512
  temperature: 0.7
  top_p: 0.9
  safe_name: medgemma_27b_text_it
prompt:
  _target_: cotlab.prompts.pubmedqa.PubMedQAPromptStrategy
  name: pubmedqa
  output_format: json
  few_shot: true
  answer_first: false
  contrarian: false
dataset:
  _target_: cotlab.datasets.loaders.PubMedQADataset
  name: pubmedqa
  filename: pubmedqa/test.jsonl
experiment:
  _target_: cotlab.experiments.ActivationPatchingExperiment
  name: activation_patching
  description: Layer-wise causal activation patching (logit recovery)
  patching_mode: introspect_contrast
  layer_stride: 2
  num_samples: 50
  max_input_tokens: 1024
  seed: 42
  answer_cue: '


    Answer:'
  introspect_instruction: Think deeply about this problem. Carefully reason through
    the underlying mechanisms and consider all relevant factors before committing
    to your answer.
seed: 42
verbose: true
dry_run: false

============================================================
Created experiment documentation: /home/ubuntu/CoTLab/outputs/2026-02-26/19-42-05_activation_patching_medgemma_27b_text_it_pubmedqa_json_pubmedqa/EXPERIMENT.md
Loading backend: cotlab.backends.TransformersBackend
Loading model: google/medgemma-27b-text-it
  Device map: cuda
  Dtype: torch.bfloat16
  Cache: ~/.cache/huggingface (HF default)
Loading checkpoint shards:   0%|                                           | 0/11 [00:00<?, ?it/s]Loading checkpoint shards:   9%|███▏                               | 1/11 [00:00<00:07,  1.42it/s]Loading checkpoint shards:  18%|██████▎                            | 2/11 [00:01<00:06,  1.40it/s]Loading checkpoint shards:  27%|█████████▌                         | 3/11 [00:02<00:05,  1.41it/s]Loading checkpoint shards:  36%|████████████▋                      | 4/11 [00:02<00:05,  1.40it/s]Loading checkpoint shards:  45%|███████████████▉                   | 5/11 [00:03<00:04,  1.42it/s]Loading checkpoint shards:  55%|███████████████████                | 6/11 [00:04<00:03,  1.43it/s]Loading checkpoint shards:  64%|██████████████████████▎            | 7/11 [00:04<00:02,  1.40it/s]Loading checkpoint shards:  73%|█████████████████████████▍         | 8/11 [00:05<00:02,  1.40it/s]Loading checkpoint shards:  82%|████████████████████████████▋      | 9/11 [00:06<00:01,  1.42it/s]Loading checkpoint shards:  91%|██████████████████████████████▉   | 10/11 [00:07<00:00,  1.44it/s]Loading checkpoint shards: 100%|██████████████████████████████████| 11/11 [00:07<00:00,  1.47it/s]Loading checkpoint shards: 100%|██████████████████████████████████| 11/11 [00:07<00:00,  1.43it/s]
  Resolved device: cuda:0
Creating prompt strategy: pubmedqa
Loading dataset: pubmedqa
Creating experiment: activation_patching
============================================================
Running experiment: activation_patching
============================================================
Model        : google/medgemma-27b-text-it
Patching mode: introspect_contrast
Layers (31): [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60]
Stride : 2  |  max_input_tokens: 1024
Samples: 50  (each requires 33 forward passes)

Activation patching:   0%|                                                 | 0/50 [00:00<?, ?it/s]Activation patching:   2%|▊                                        | 1/50 [00:04<03:34,  4.37s/it]Activation patching:   4%|█▋                                       | 2/50 [00:09<03:51,  4.81s/it]Activation patching:   6%|██▍                                      | 3/50 [00:14<03:49,  4.89s/it]Activation patching:   8%|███▎                                     | 4/50 [00:19<03:41,  4.81s/it]Activation patching:  10%|████                                     | 5/50 [00:23<03:33,  4.74s/it]Activation patching:  12%|████▉                                    | 6/50 [00:28<03:35,  4.89s/it]Activation patching:  14%|█████▋                                   | 7/50 [00:33<03:20,  4.67s/it]Activation patching:  16%|██████▌                                  | 8/50 [00:37<03:14,  4.62s/it]Activation patching:  18%|███████▍                                 | 9/50 [00:41<03:03,  4.46s/it]Activation patching:  20%|████████                                | 10/50 [00:46<03:04,  4.62s/it]Activation patching:  22%|████████▊                               | 11/50 [00:51<02:58,  4.58s/it]Activation patching:  24%|█████████▌                              | 12/50 [00:56<02:59,  4.72s/it]Activation patching:  26%|██████████▍                             | 13/50 [01:00<02:43,  4.43s/it]Activation patching:  28%|███████████▏                            | 14/50 [01:04<02:38,  4.39s/it]Activation patching:  30%|████████████                            | 15/50 [01:08<02:34,  4.43s/it]Activation patching:  32%|████████████▊                           | 16/50 [01:13<02:34,  4.54s/it]Activation patching:  34%|█████████████▌                          | 17/50 [01:17<02:26,  4.45s/it]Activation patching:  36%|██████████████▍                         | 18/50 [01:22<02:25,  4.55s/it]Activation patching:  38%|███████████████▏                        | 19/50 [01:27<02:27,  4.76s/it]Activation patching:  40%|████████████████                        | 20/50 [01:33<02:27,  4.90s/it]Activation patching:  42%|████████████████▊                       | 21/50 [01:37<02:18,  4.79s/it]Activation patching:  44%|█████████████████▌                      | 22/50 [01:42<02:16,  4.88s/it]Activation patching:  46%|██████████████████▍                     | 23/50 [01:46<02:03,  4.59s/it]Activation patching:  48%|███████████████████▏                    | 24/50 [01:51<02:00,  4.64s/it]Activation patching:  50%|████████████████████                    | 25/50 [01:56<01:57,  4.68s/it]Activation patching:  52%|████████████████████▊                   | 26/50 [02:01<01:53,  4.75s/it]Activation patching:  54%|█████████████████████▌                  | 27/50 [02:05<01:49,  4.76s/it]Activation patching:  56%|██████████████████████▍                 | 28/50 [02:10<01:43,  4.71s/it]Activation patching:  58%|███████████████████████▏                | 29/50 [02:15<01:40,  4.79s/it]Activation patching:  60%|████████████████████████                | 30/50 [02:20<01:35,  4.79s/it]Activation patching:  62%|████████████████████████▊               | 31/50 [02:25<01:31,  4.84s/it]Activation patching:  64%|█████████████████████████▌              | 32/50 [02:29<01:22,  4.56s/it]Activation patching:  66%|██████████████████████████▍             | 33/50 [02:33<01:17,  4.54s/it]Activation patching:  68%|███████████████████████████▏            | 34/50 [02:38<01:15,  4.74s/it]Activation patching:  70%|████████████████████████████            | 35/50 [02:44<01:13,  4.91s/it]Activation patching:  72%|████████████████████████████▊           | 36/50 [02:48<01:07,  4.84s/it]Activation patching:  74%|█████████████████████████████▌          | 37/50 [02:53<01:02,  4.78s/it]Activation patching:  76%|██████████████████████████████▍         | 38/50 [02:58<00:59,  4.94s/it]Activation patching:  78%|███████████████████████████████▏        | 39/50 [03:03<00:53,  4.84s/it]Activation patching:  80%|████████████████████████████████        | 40/50 [03:08<00:48,  4.86s/it]Activation patching:  82%|████████████████████████████████▊       | 41/50 [03:12<00:42,  4.77s/it]Activation patching:  84%|█████████████████████████████████▌      | 42/50 [03:17<00:36,  4.58s/it]Activation patching:  86%|██████████████████████████████████▍     | 43/50 [03:21<00:32,  4.67s/it]Activation patching:  88%|███████████████████████████████████▏    | 44/50 [03:26<00:28,  4.76s/it]Activation patching:  90%|████████████████████████████████████    | 45/50 [03:31<00:24,  4.80s/it]Activation patching:  92%|████████████████████████████████████▊   | 46/50 [03:37<00:20,  5.04s/it]Activation patching:  94%|█████████████████████████████████████▌  | 47/50 [03:42<00:15,  5.00s/it]Activation patching:  96%|██████████████████████████████████████▍ | 48/50 [03:47<00:09,  4.98s/it]Activation patching:  98%|███████████████████████████████████████▏| 49/50 [03:51<00:04,  4.89s/it]Activation patching: 100%|████████████████████████████████████████| 50/50 [03:56<00:00,  4.89s/it]Activation patching: 100%|████████████████████████████████████████| 50/50 [03:56<00:00,  4.74s/it]

==============================================================
ACTIVATION PATCHING SUMMARY  (logit-recovery effect)
==============================================================
Processed samples : 50 / 50
Top-5 causal layers: [0, 8, 40, 24, 26]

 Layer   Mean Effect   N samples
----------------------------------
     0        0.6859          50
     2        0.1790          50
     4        0.1745          50
     6        0.2013          50
     8        0.6721          50
    10        0.2475          50
    12        0.1958          50
    14        0.3546          50
    16        0.2694          50
    18        0.3848          50
    20        0.2800          50
    22        0.6093          50
    24        0.6400          50
    26        0.6400          50
    28        0.6400          50
    30        0.5542          50
    32        0.3625          50
    34        0.2617          50
    36        0.6164          50
    38        0.3617          50
    40        0.6488          50
    42        0.3288          50
    44        0.2920          50
    46        0.5442          50
    48        0.2887          50
    50        0.0220          50
    52        0.2240          50
    54        0.1358          50
    56        0.1964          50
    58       -0.0148          50
    60        0.0073          50
==============================================================

Results saved to: /home/ubuntu/CoTLab/outputs/2026-02-26/19-42-05_activation_patching_medgemma_27b_text_it_pubmedqa_json_pubmedqa/results.json

Metrics:
  num_samples: 50
  layer_stride: 2
  mean_effect_per_layer: {0: 0.6859, 2: 0.179, 4: 0.1745, 6: 0.2013, 8: 0.6721, 10: 0.2475, 12: 0.1958, 14: 0.3546, 16: 0.2694, 18: 0.3848, 20: 0.28, 22: 0.6093, 24: 0.64, 26: 0.64, 28: 0.64, 30: 0.5542, 32: 0.3625, 34: 0.2617, 36: 0.6164, 38: 0.3617, 40: 0.6488, 42: 0.3288, 44: 0.292, 46: 0.5442, 48: 0.2887, 50: 0.022, 52: 0.224, 54: 0.1358, 56: 0.1964, 58: -0.0148, 60: 0.0073}
  top_5_causal_layers: [0, 8, 40, 24, 26]

Experiment documentation updated: /home/ubuntu/CoTLab/outputs/2026-02-26/19-42-05_activation_patching_medgemma_27b_text_it_pubmedqa_json_pubmedqa/EXPERIMENT.md

Experiment complete.
