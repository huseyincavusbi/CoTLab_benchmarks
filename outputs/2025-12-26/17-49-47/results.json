{
  "metadata": {
    "config": {
      "backend": {
        "_target_": "cotlab.backends.TransformersBackend",
        "device": "cuda",
        "dtype": "bfloat16",
        "enable_hooks": true,
        "trust_remote_code": true
      },
      "model": {
        "name": "google/medgemma-4b-it",
        "variant": "4b",
        "max_new_tokens": 512,
        "temperature": 0.7,
        "top_p": 0.9
      },
      "prompt": {
        "_target_": "cotlab.prompts.length_matched_strategies.ChainOfThoughtMatchedStrategy",
        "name": "cot_matched"
      },
      "dataset": {
        "_target_": "cotlab.datasets.PatchingPairsDataset",
        "name": "patching_pairs",
        "path": "data/Patching_Pairs_Data.csv"
      },
      "experiment": {
        "_target_": "cotlab.experiments.AttentionAnalysisExperiment",
        "name": "attention_analysis",
        "description": "Analyze attention patterns at critical layers",
        "target_layers": [
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33
        ],
        "num_samples": 20
      },
      "seed": 42,
      "verbose": true,
      "dry_run": false
    },
    "start_time": "2025-12-26T17:49:47.523888"
  },
  "experiment": "attention_analysis",
  "model": "google/medgemma-4b-it",
  "prompt_strategy": "cot_matched",
  "metrics": {
    "num_samples_analyzed": 20,
    "num_layers_analyzed": 9,
    "num_heads": 8,
    "overall_mean_entropy": 1.658796861436632,
    "most_focused_layer": 28,
    "most_focused_entropy": 1.2466033935546874
  },
  "raw_outputs": [
    {
      "layer": 25,
      "mean_entropy": 1.429638671875,
      "std_entropy": 0.05680264156404669,
      "mean_per_head": [
        0.5634765625,
        1.2587890625,
        1.359375,
        1.49140625,
        2.36171875,
        1.729296875,
        1.18359375,
        1.489453125
      ],
      "std_per_head": [
        0.10655813974538075,
        0.09394409432682141,
        0.09735892237296488,
        0.11431105196595168,
        0.09060816115112091,
        0.12184181739779194,
        0.14018485807530623,
        0.08619545801503624
      ],
      "top_tokens": [
        {
          "token": "<bos>",
          "count": 20
        },
        {
          "token": " analysis",
          "count": 14
        },
        {
          "token": "\n\n",
          "count": 8
        },
        {
          "token": " Patient",
          "count": 2
        },
        {
          "token": " Provide",
          "count": 2
        }
      ]
    },
    {
      "layer": 26,
      "mean_entropy": 1.865380859375,
      "std_entropy": 0.1154554515815353,
      "mean_per_head": [
        1.809375,
        2.169921875,
        1.113671875,
        2.56328125,
        1.547265625,
        2.21875,
        1.931640625,
        1.569140625
      ],
      "std_per_head": [
        0.24962618536899328,
        0.17103621678221217,
        0.11679556855456621,
        0.24811176562627477,
        0.16800462916218073,
        0.08356088723200586,
        0.02151985706381144,
        0.10057436978386629
      ],
      "top_tokens": [
        {
          "token": "<bos>",
          "count": 20
        },
        {
          "token": "\n\n",
          "count": 16
        },
        {
          "token": ".",
          "count": 11
        },
        {
          "token": "oma",
          "count": 1
        },
        {
          "token": " CT",
          "count": 1
        }
      ]
    },
    {
      "layer": 27,
      "mean_entropy": 1.47001953125,
      "std_entropy": 0.03660616557714162,
      "mean_per_head": [
        0.40517578125,
        3.1796875,
        0.8158203125,
        1.32890625,
        0.63671875,
        0.33291015625,
        2.83359375,
        2.22734375
      ],
      "std_per_head": [
        0.038095827041342296,
        0.07452650011069888,
        0.043292019051716896,
        0.030247594816571778,
        0.031201133668306028,
        0.01901139208934487,
        0.1300047888240564,
        0.09801185255971595
      ],
      "top_tokens": [
        {
          "token": "<bos>",
          "count": 20
        },
        {
          "token": " analysis",
          "count": 20
        },
        {
          "token": "You",
          "count": 20
        }
      ]
    },
    {
      "layer": 28,
      "mean_entropy": 1.2466033935546874,
      "std_entropy": 0.03307177578905708,
      "mean_per_head": [
        2.446875,
        1.076953125,
        1.150390625,
        0.1018310546875,
        2.078515625,
        2.19609375,
        0.33857421875,
        0.58359375
      ],
      "std_per_head": [
        0.13660933121496496,
        0.1773114817835146,
        0.03191432546556287,
        0.012014571680696457,
        0.08007240833253285,
        0.06470240619318188,
        0.04408733560798092,
        0.03782008575768635
      ],
      "top_tokens": [
        {
          "token": "<bos>",
          "count": 20
        },
        {
          "token": " analysis",
          "count": 20
        },
        {
          "token": " your",
          "count": 11
        },
        {
          "token": ":",
          "count": 9
        }
      ]
    },
    {
      "layer": 29,
      "mean_entropy": 1.452197265625,
      "std_entropy": 0.052552118770813,
      "mean_per_head": [
        1.52578125,
        1.0578125,
        1.525390625,
        2.02109375,
        1.44375,
        1.741015625,
        0.433203125,
        1.86953125
      ],
      "std_per_head": [
        0.11807218147837574,
        0.06363232091967885,
        0.16596506583064966,
        0.1256112982266623,
        0.16265392349440883,
        0.17122168091007597,
        0.04451497098282287,
        0.10397084458364997
      ],
      "top_tokens": [
        {
          "token": "<bos>",
          "count": 20
        },
        {
          "token": " analysis",
          "count": 20
        },
        {
          "token": "\n\n",
          "count": 15
        },
        {
          "token": ":",
          "count": 5
        }
      ]
    },
    {
      "layer": 30,
      "mean_entropy": 2.214599609375,
      "std_entropy": 0.13421496242734557,
      "mean_per_head": [
        1.994921875,
        2.4640625,
        2.23828125,
        2.0265625,
        2.40078125,
        2.39375,
        2.18359375,
        2.01484375
      ],
      "std_per_head": [
        0.10409331727431821,
        0.14516121156751896,
        0.17600679973991773,
        0.20243874459327196,
        0.14701414618902325,
        0.15202089186194115,
        0.1459809056167535,
        0.19585705336178857
      ],
      "top_tokens": [
        {
          "token": "<bos>",
          "count": 20
        },
        {
          "token": " medical",
          "count": 2
        },
        {
          "token": " erythe",
          "count": 2
        },
        {
          "token": "ma",
          "count": 2
        },
        {
          "token": " lymphoma",
          "count": 2
        }
      ]
    },
    {
      "layer": 31,
      "mean_entropy": 1.893212890625,
      "std_entropy": 0.03980146670202859,
      "mean_per_head": [
        0.5611328125,
        1.1294921875,
        1.605078125,
        2.56640625,
        2.4015625,
        2.56640625,
        1.6140625,
        2.7015625
      ],
      "std_per_head": [
        0.06325260974189252,
        0.16508828777726925,
        0.11222500569969636,
        0.07841742148392473,
        0.0714491460323355,
        0.07572485014635222,
        0.08236168566527155,
        0.14978011226878557
      ],
      "top_tokens": [
        {
          "token": "<bos>",
          "count": 20
        },
        {
          "token": " analysis",
          "count": 20
        },
        {
          "token": " Provide",
          "count": 18
        },
        {
          "token": ".",
          "count": 2
        }
      ]
    },
    {
      "layer": 32,
      "mean_entropy": 1.50069580078125,
      "std_entropy": 0.058869350775830255,
      "mean_per_head": [
        1.581640625,
        1.72734375,
        1.68203125,
        2.29921875,
        0.7484375,
        0.81943359375,
        2.43984375,
        0.7076171875
      ],
      "std_per_head": [
        0.20651431631196146,
        0.19908696621624306,
        0.07031684014382686,
        0.041420987943161146,
        0.11605836228825242,
        0.1255518746938322,
        0.06541540189196654,
        0.07211528915007703
      ],
      "top_tokens": [
        {
          "token": "<bos>",
          "count": 20
        },
        {
          "token": ":",
          "count": 13
        },
        {
          "token": "\n\n",
          "count": 10
        },
        {
          "token": " analysis",
          "count": 8
        },
        {
          "token": " your",
          "count": 7
        }
      ]
    },
    {
      "layer": 33,
      "mean_entropy": 1.85682373046875,
      "std_entropy": 0.05544983850383373,
      "mean_per_head": [
        2.9984375,
        1.506640625,
        1.84375,
        2.08828125,
        1.0267578125,
        2.5453125,
        2.34375,
        0.50166015625
      ],
      "std_per_head": [
        0.08613613407711077,
        0.07723220333786857,
        0.060110575192722955,
        0.07998183997985106,
        0.2640760068429858,
        0.21377718211668426,
        0.07509759275436198,
        0.048433069826386364
      ],
      "top_tokens": [
        {
          "token": ":",
          "count": 20
        },
        {
          "token": "<bos>",
          "count": 20
        },
        {
          "token": " analysis",
          "count": 20
        }
      ]
    }
  ],
  "num_samples": 0,
  "samples": [],
  "end_time": "2025-12-26T17:49:59.036038",
  "duration_seconds": 11.512152
}